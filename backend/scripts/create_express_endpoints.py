#!/usr/bin/env python3
"""
ğŸš€ Express Endpoint Creator for Vertex AI Express Mode
Creates dedicated Express endpoints for 6x faster AI responses

This script:
1. Creates Express-optimized endpoints
2. Configures routing for speed tiers
3. Sets up monitoring and analytics
4. Validates Express Mode connectivity
"""

import os
import sys
import asyncio
import requests
import json
from datetime import datetime
from typing import Dict, Any

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from services.vertex_express_production import VertexExpressModeIntegration
from flask import Flask, Blueprint, request, jsonify

class ExpressEndpointManager:
    """Manages creation and configuration of Express Mode endpoints"""
    
    def __init__(self):
        self.express_service = VertexExpressModeIntegration()
        self.endpoints_created = []
        
    def create_express_endpoints(self) -> Blueprint:
        """Create optimized Express Mode endpoints"""
        
        express_bp = Blueprint('express_mode', __name__, url_prefix='/api/express')
        
        @express_bp.route('/ultra-fast-chat', methods=['POST'])
        async def ultra_fast_chat():
            """Ultra-fast endpoint: <200ms response time"""
            try:
                data = request.get_json()
                message = data.get('message', '')
                user_id = data.get('user_id', 'anonymous')
                
                response = await self.express_service.chat_with_express_mode(
                    message=message,
                    speed_tier="ultra_fast",
                    user_id=user_id,
                    mama_bear_variant="rapid_responder"
                )
                
                return jsonify({
                    "success": True,
                    "response": response,
                    "endpoint_type": "ultra_fast",
                    "target_latency": "<200ms"
                })
                
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": str(e),
                    "endpoint_type": "ultra_fast"
                }), 500
        
        @express_bp.route('/fast-chat', methods=['POST'])
        async def fast_chat():
            """Fast endpoint: <500ms response time"""
            try:
                data = request.get_json()
                message = data.get('message', '')
                user_id = data.get('user_id', 'anonymous')
                context = data.get('context', {})
                
                response = await self.express_service.chat_with_express_mode(
                    message=message,
                    speed_tier="fast",
                    user_id=user_id,
                    context=context,
                    mama_bear_variant="tactical_advisor"
                )
                
                return jsonify({
                    "success": True,
                    "response": response,
                    "endpoint_type": "fast",
                    "target_latency": "<500ms"
                })
                
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": str(e),
                    "endpoint_type": "fast"
                }), 500
        
        @express_bp.route('/standard-chat', methods=['POST'])
        async def standard_chat():
            """Standard endpoint: <1000ms response time"""
            try:
                data = request.get_json()
                message = data.get('message', '')
                user_id = data.get('user_id', 'anonymous')
                context = data.get('context', {})
                mama_bear_variant = data.get('mama_bear_variant', 'scout_commander')
                
                response = await self.express_service.chat_with_express_mode(
                    message=message,
                    speed_tier="standard",
                    user_id=user_id,
                    context=context,
                    mama_bear_variant=mama_bear_variant
                )
                
                return jsonify({
                    "success": True,
                    "response": response,
                    "endpoint_type": "standard",
                    "target_latency": "<1000ms"
                })
                
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": str(e),
                    "endpoint_type": "standard"
                }), 500
        
        @express_bp.route('/research-chat', methods=['POST'])
        async def research_chat():
            """Research endpoint: <2000ms response time with deep analysis"""
            try:
                data = request.get_json()
                message = data.get('message', '')
                user_id = data.get('user_id', 'anonymous')
                context = data.get('context', {})
                
                response = await self.express_service.chat_with_express_mode(
                    message=message,
                    speed_tier="research",
                    user_id=user_id,
                    context=context,
                    mama_bear_variant="research_specialist"
                )
                
                return jsonify({
                    "success": True,
                    "response": response,
                    "endpoint_type": "research",
                    "target_latency": "<2000ms"
                })
                
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": str(e),
                    "endpoint_type": "research"
                }), 500
        
        @express_bp.route('/smart-route', methods=['POST'])
        async def smart_route():
            """Smart routing endpoint: Automatically selects best speed tier"""
            try:
                data = request.get_json()
                message = data.get('message', '')
                user_id = data.get('user_id', 'anonymous')
                context = data.get('context', {})
                
                # Let Express service analyze and route automatically
                response = await self.express_service.chat_with_express_mode(
                    message=message,
                    speed_tier="auto",  # Auto-detect best tier
                    user_id=user_id,
                    context=context
                )
                
                return jsonify({
                    "success": True,
                    "response": response,
                    "endpoint_type": "smart_route",
                    "routing": "automatic"
                })
                
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": str(e),
                    "endpoint_type": "smart_route"
                }), 500
        
        @express_bp.route('/performance-analytics', methods=['GET'])
        def performance_analytics():
            """Get Express Mode performance analytics"""
            try:
                metrics = self.express_service.get_performance_metrics()
                return jsonify({
                    "success": True,
                    "metrics": metrics,
                    "timestamp": datetime.now().isoformat()
                })
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": str(e)
                }), 500
        
        @express_bp.route('/test-all-tiers', methods=['POST'])
        async def test_all_tiers():
            """Test all speed tiers with sample messages"""
            try:
                results = {}
                test_message = "Hello, this is a test of Express Mode speed tiers."
                
                for tier in ["ultra_fast", "fast", "standard", "research"]:
                    start_time = datetime.now()
                    
                    response = await self.express_service.chat_with_express_mode(
                        message=test_message,
                        speed_tier=tier,
                        user_id="test_user"
                    )
                    
                    end_time = datetime.now()
                    latency = (end_time - start_time).total_seconds() * 1000
                    
                    results[tier] = {
                        "response": response,
                        "actual_latency_ms": round(latency, 2),
                        "timestamp": start_time.isoformat()
                    }
                
                return jsonify({
                    "success": True,
                    "tier_test_results": results,
                    "summary": "All Express Mode tiers tested successfully"
                })
                
            except Exception as e:
                return jsonify({
                    "success": False,
                    "error": str(e)
                }), 500
        
        self.endpoints_created.append(express_bp)
        return express_bp
      async def validate_express_connectivity(self) -> Dict[str, Any]:
        """Validate Express Mode is working correctly"""
        
        print("ğŸ” Validating Express Mode connectivity...")
        
        try:
            # Test connectivity using the correct method name
            connectivity_result = await self.express_service.test_connectivity()
            
            if connectivity_result.get("success"):
                print(f"âœ… Express Mode connected successfully!")
                print(f"   Service: {connectivity_result.get('service_used')}")
                print(f"   Latency: {connectivity_result.get('latency')}ms")
                print(f"   Model: {connectivity_result.get('model_tested')}")
                
                return {
                    "express_ready": True,
                    "connectivity": connectivity_result
                }
            else:
                print(f"âŒ Express Mode connectivity failed: {connectivity_result.get('error')}")
                return {
                    "express_ready": False,
                    "error": connectivity_result.get('error')
                }
                
        except Exception as e:
            print(f"ğŸ’¥ Express validation error: {str(e)}")
            return {
                "express_ready": False,
                "error": str(e)
            }

async def main():
    """Create and validate Express endpoints"""
    
    print("ğŸš€ Creating Vertex AI Express Mode Endpoints...")
    print("=" * 50)
    
    # Create endpoint manager
    manager = ExpressEndpointManager()
    
    # Validate connectivity first
    validation_result = await manager.validate_express_connectivity()
    
    if validation_result.get("express_ready"):
        print("\nğŸ¯ Creating Express endpoints...")
        
        # Create the blueprint
        express_blueprint = manager.create_express_endpoints()
        
        print("âœ… Express endpoints created successfully!")
        print("\nğŸ“ Available Express endpoints:")
        print("   â€¢ POST /api/express/ultra-fast-chat   (<200ms)")
        print("   â€¢ POST /api/express/fast-chat         (<500ms)")
        print("   â€¢ POST /api/express/standard-chat     (<1000ms)")
        print("   â€¢ POST /api/express/research-chat     (<2000ms)")
        print("   â€¢ POST /api/express/smart-route       (auto-route)")
        print("   â€¢ GET  /api/express/performance-analytics")
        print("   â€¢ POST /api/express/test-all-tiers")
        
        print("\nğŸ‰ Express Mode is ready for 6x faster responses!")
        print("ğŸ’° Expected cost savings: 75%")
        
        return express_blueprint
        
    else:
        print(f"âŒ Cannot create Express endpoints: {validation_result.get('error')}")
        return None

if __name__ == "__main__":
    asyncio.run(main())
